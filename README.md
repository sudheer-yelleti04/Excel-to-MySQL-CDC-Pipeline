

---

# ðŸ“Š Excel to MySQL CDC Pipeline

A **Python-based batch ETL & CDC (Change Data Capture) pipeline** that ingests data from an Excel file into MySQL with:

* **Historic layer** (append-only, full audit)
* **CDC layer** (latest active snapshot)
* **Archive layer** (file-level metadata tracking)

This project demonstrates **real-world data engineering concepts** such as CDC, layered storage, auditability, and batch ingestion.

---

## ðŸ—ï¸ High-Level Architecture

```
Excel File (.xlsx)
        â”‚
        â–¼
Python ETL Script (Pandas + CDC Logic)
        â”‚
        â–¼
MySQL Database
 â”œâ”€â”€ historic_layer  (Full History)
 â”œâ”€â”€ cdc_layer       (Latest Snapshot)
 â””â”€â”€ archive_layer   (Metadata)
```

---

## ðŸ“‚ Project Folder Structure

```
excel-mysql-cdc-pipeline/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ referrals_data.xlsx
â”‚   â”‚
â”‚   â””â”€â”€ archive/
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ logs/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ðŸ“ Folder Description

| Folder/File           | Purpose                       |
| --------------------- | ----------------------------- |
| `data/raw`            | Source Excel files            |
| `data/archive`        | Logical archive reference     |
| `src/main.py`         | Main ETL + CDC logic          |
| `config/.env.example` | Environment variable template |
| `logs`                | Execution logs (optional)     |
| `requirements.txt`    | Python dependencies           |
| `README.md`           | Project documentation         |

---

## âš™ï¸ Prerequisites

Before running the project, ensure you have:

* Python **3.8+**
* MySQL **5.7+ / 8.x**
* Git
* MySQL user with CREATE & INSERT privileges

---

## ðŸ§° Python Dependencies

Install required libraries using:

```bash
pip install -r requirements.txt
```

### `requirements.txt`

```txt
pandas
mysql-connector-python
python-dotenv
openpyxl
```

---

## ðŸ” Environment Configuration

Create a `.env` file inside the `config/` directory.

### `.env.example`

```env
DB_HOST=localhost
DB_USER=root
DB_PASSWORD=your_password
DB_NAME=cdc_db
EXCEL_FILE=data/raw/referrals_data.xlsx
```

ðŸ“Œ **Important**

* Do NOT commit `.env` to GitHub
* Add `.env` to `.gitignore`

---

## ðŸ—ƒï¸ Database Schema Design

### Common Schema Used

```sql
S_n0              INT
Refferal Person   VARCHAR(100)
LinkedIn          VARCHAR(255)
Company Name      VARCHAR(150)
Career Portal     VARCHAR(255)
Year              INT
Statusflag        CHAR(1)
Timestamp         DATETIME
load_ts           DATETIME (auto)
```

---

## ðŸ—„ï¸ Database Tables

### 1ï¸âƒ£ `historic_layer`

* Append-only table
* Stores **every version** of every record
* Used for:

  * Audit
  * Time travel
  * Debugging

---

### 2ï¸âƒ£ `cdc_layer`

* Stores **latest active record per business key**
* Primary Key: `S_n0`
* Refreshed on every run

---

### 3ï¸âƒ£ `archive_layer`

Tracks ingestion metadata:

| Column       | Description                 |
| ------------ | --------------------------- |
| file_name    | Source file name            |
| processed_at | Load timestamp              |
| record_count | Number of records processed |

---

## ðŸ” Step-by-Step Execution Flow

### âœ… Step 1: Load Environment Variables

* Reads database credentials
* Reads Excel file path

```python
load_dotenv()
```

---

### âœ… Step 2: Read Excel File

* Loads Excel into Pandas DataFrame
* Converts `Timestamp` column to datetime

```python
raw_df = pd.read_excel(RAW_EXCEL_FILE)
raw_df["Timestamp"] = pd.to_datetime(raw_df["Timestamp"])
```

---

### âœ… Step 3: Connect to MySQL

* Uses `mysql-connector-python`
* Opens cursor for execution

---

### âœ… Step 4: Create Tables (If Not Exists)

* `historic_layer`
* `cdc_layer`
* `archive_layer`

Ensures idempotent execution.

---

### âœ… Step 5: Load Historic Layer

* Inserts **all incoming records**
* No updates or deletes

```text
Excel â†’ historic_layer
```

ðŸ“Œ Purpose: Maintain full data history.

---

### âœ… Step 6: Load Existing CDC Data

* Reads current snapshot from `cdc_layer`
* Converts it into Pandas DataFrame

---

### âœ… Step 7: Apply CDC Logic

**CDC Rules Implemented:**

1. Combine existing CDC + new data
2. Sort by:

   * Business Key (`S_n0`)
   * Timestamp (DESC)
3. Keep latest record per key
4. Exclude deleted records (`Statusflag = 'D'`)

```text
Latest record wins
Deleted records removed
```

---

### âœ… Step 8: Refresh CDC Layer

* Truncates `cdc_layer`
* Inserts latest active records

ðŸ“Œ CDC layer always represents **current state**

---

### âœ… Step 9: Archive File Metadata

* Stores:

  * File name
  * Processing time
  * Record count

Used for monitoring & audit.

---

### âœ… Step 10: Close Connections

* Safely closes cursor and DB connection

---

## â–¶ï¸ How to Run the Project

```bash
python src/main.py
```

Expected output:

```text
Connected to MySQL
Tables ensured
Historic layer updated
CDC layer refreshed
File archived in DB
MySQL connection closed
```

---

## ðŸŽ¯ Key Data Engineering Concepts Demonstrated

* Batch ETL
* Change Data Capture (CDC)
* Layered data modeling
* Append-only history
* Current-state snapshot
* Metadata & audit tracking
* Idempotent table creation

---

## ðŸš€ Future Enhancements

* Incremental file ingestion
* File checksum validation
* Airflow orchestration
* Spark-based CDC
* Cloud migration (S3 + RDS)
* Data quality checks

---

## ðŸ§¾ Summary

> Designed and implemented a Python-based batch CDC pipeline ingesting Excel data into MySQL with historical tracking, current-state snapshots, and audit metadata using Pandas and SQL.

---

## ðŸ‘¤ Author

**Yelleti Sudheer Kumar**
Big Data & Data Engineering Enthusiast

---

